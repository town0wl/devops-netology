### Часть 1

Создаем для базы данных статический PV на ноде, чтобы избежать задержки обращения по сети:
```
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-postgres
spec:
  storageClassName: ""
  accessModes:
    - ReadWriteOnce
  capacity:
    storage: 2Gi
  hostPath:
    path: /data/pv-postgres
```

Создаем PVC для базы данных:
```
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: pvc-postgres-demo
spec:
  storageClassName: ""
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 2Gi
```

Создаем сервис для базы данных (headless сервис создаст доменные имена, чтобы обращаться к конкретным репликам по `$`(podname).`$`(service name).$(namespace).svc.cluster.local, но наше приложение ходит по имени "db", поэтому создаем ClusterIP):
```
apiVersion: v1
kind: Service
metadata:
  name: db
  labels:
    app: postgres-demo
spec:
  ports:
  - port: 5432
  selector:
    app: postgres-demo
```

Параметры доступа к СУБД упакуем в секрет:
```
apiVersion: v1
kind: Secret
metadata:
  name: postgres-demo-secrets
  labels:
    app: postgres-demo
data:
  POSTGRES_DB: bmV3cw==
  POSTGRES_USER: cG9zdGdyZXM=
  POSTGRES_PASSWORD: bm90YXBvc3RncmVz
```

Собираем StatefulSet для СУБД:
```
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: ss-postgres
  labels:
    app: postgres-demo
spec:
  serviceName: db
  replicas: 1
  selector:
    matchLabels:
      app: postgres-demo
  template:
    metadata:
      labels:
        app: postgres-demo
    spec:
      serviceAccountName: postgres-demo-sa
      automountServiceAccountToken: false
      containers:
      - name: postgres
        image: postgres:12-alpine
        envFrom:
        - secretRef:
            name: postgres-demo-secrets
        ports:
        - containerPort: 5432
        volumeMounts:
        - name: postgres-data
          mountPath: /var/lib/postgresql/data
      volumes:
      - name: postgres-data
        persistentVolumeClaim:
          claimName: pvc-postgres-demo
```

Проверка сервиса:
```
[kube:homeworks]$ kl get pod,statefulset,service -n app1 -o wide
NAME                READY   STATUS    RESTARTS   AGE   IP             NODE    NOMINATED NODE   READINESS GATES
pod/ss-postgres-0   1/1     Running   0          59s   10.234.44.31   node2   <none>           <none>

NAME                           READY   AGE     CONTAINERS   IMAGES
statefulset.apps/ss-postgres   1/1     8m36s   postgres     postgres:12-alpine

NAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE     SELECTOR
service/db   ClusterIP   10.111.57.183   <none>        5432/TCP   8m36s   app=postgres-demo

[kube:homeworks]$ kl port-forward -n app1 service/db 5432:5432 &
[2] 3937
Forwarding from 127.0.0.1:5432 -> 5432
Forwarding from [::1]:5432 -> 5432
[kube:homeworks]$ psql -h 127.0.0.1 -p 5432 -U postgres
Handling connection for 5432
psql (14.3 (Debian 14.3-1), server 12.11)
Type "help" for help.

postgres=#
```

Фронт запустится на 80 порту пода, бэк будет доступен ему локально на 9000 порту, параметры для подключения к СУБД вшиты в .env в образе бэка:
```
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: stage
  name: stage-deploy
spec:
  replicas: 2
  selector:
    matchLabels:
      app: stage
  template:
    metadata:
      labels:
        app: stage
    spec:
      automountServiceAccountToken: false
      containers:
      - image: town0wl/netology-repo:frontend
        imagePullPolicy: IfNotPresent
        name: frontend
        resources:
          limits:
            cpu: 200m
            memory: 512Mi
          requests:
            cpu: 100m
            memory: 256Mi
      - image: town0wl/netology-repo:backend
        imagePullPolicy: IfNotPresent
        name: backend
        resources:
          limits:
            cpu: 200m
            memory: 512Mi
          requests:
            cpu: 100m
            memory: 256Mi
```

Все запустилось на одной ноде (т.к. на другой Vault выжрал всю память):
```
[kube:homeworks]$ kl get pod -n app1 -o wide
NAME                           READY   STATUS    RESTARTS   AGE   IP             NODE    NOMINATED NODE   READINESS GATES
ss-postgres-0                  1/1     Running   0          16m   10.234.44.31   node2   <none>           <none>
stage-deploy-d45cf8cd9-pn7bh   2/2     Running   0          51s   10.234.44.32   node2   <none>           <none>
stage-deploy-d45cf8cd9-wrh9c   2/2     Running   0          51s   10.234.44.33   node2   <none>           <none>
[kube:homeworks]$ kl get nodes -o wide
NAME      STATUS   ROLES           AGE   VERSION   INTERNAL-IP   EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION      CONTAINER-RUNTIME
master1   Ready    control-plane   11d   v1.24.2   10.7.1.13     <none>        Ubuntu 20.04.4 LTS   5.4.0-121-generic   containerd://1.6.6
node1     Ready    <none>          11d   v1.24.2   10.7.1.5      <none>        Ubuntu 20.04.4 LTS   5.4.0-121-generic   containerd://1.6.6
node2     Ready    <none>          11d   v1.24.2   10.7.1.15     <none>        Ubuntu 20.04.4 LTS   5.4.0-121-generic   containerd://1.6.6
```
Проверка отклика:
```
[kube:homeworks]$ kl port-forward -n app1 pod/stage-deploy-d45cf8cd9-pn7bh 8888:80 &
[3] 4051
Forwarding from 127.0.0.1:8888 -> 80
Forwarding from [::1]:8888 -> 80

[kube:homeworks]$ 
[kube:homeworks]$ curl 127.0.0.1:8888
Handling connection for 8888
<!DOCTYPE html>
<html lang="ru">
<head>
    <title>Список</title>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="/build/main.css" rel="stylesheet">
</head>
<body>
    <main class="b-page">
        <h1 class="b-page__title">Список</h1>
        <div class="b-page__content b-items js-list"></div>
    </main>
    <script src="/build/main.js"></script>
</body>
</html>
```




### Часть 2

Создаем СУБД аналогично части 1 (в новом пространстве имен и с измененными именами объектов):
```
[kube:homeworks]$ kl create namespace app-prod
namespace/app-prod created
[kube:homeworks]$ kl apply -n app-prod -f files-13.1/manifests/db
persistentvolume/pv-postgres-prod created
persistentvolumeclaim/pvc-postgres-demo created
serviceaccount/postgres-demo-sa created
secret/postgres-demo-secrets created
service/db created
statefulset.apps/ss-postgres created
[kube:homeworks]$ kl get pod,service,pvc,pv -n app-prod -o wide
NAME                READY   STATUS    RESTARTS   AGE   IP              NODE    NOMINATED NODE   READINESS GATES
pod/ss-postgres-0   1/1     Running   0          10m   10.234.154.18   node1   <none>           <none>

NAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE   SELECTOR
service/db   ClusterIP   10.111.137.58   <none>        5432/TCP   12m   app=postgres-prod

NAME                                      STATUS   VOLUME             CAPACITY   ACCESS MODES   STORAGECLASS   AGE     VOLUMEMODE
persistentvolumeclaim/pvc-postgres-prod   Bound    pv-postgres-prod   2Gi        RWO                           7m17s   Filesystem

NAME                                                        CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                        STORAGECLASS   REASON   AGE   VOLUMEMODE
persistentvolume/pv-postgres                                2Gi        RWO            Retain           Bound    app1/pvc-postgres-demo                               10h   Filesystem
persistentvolume/pv-postgres-prod                           2Gi        RWO            Retain           Bound    app-prod/pvc-postgres-prod                           50s   Filesystem

[kube:homeworks]$ kl port-forward service/db -n app-prod 5555:5432 &
[1] 5031
[kube:homeworks]$ Forwarding from 127.0.0.1:5555 -> 5432
Forwarding from [::1]:5555 -> 5432

[kube:homeworks]$ psql -h 127.0.0.1 -p 5555 -U postgres
Handling connection for 5555
psql (14.3 (Debian 14.3-1), server 12.11)
Type "help" for help.

postgres=#
```

Создаем секрет для бэка, который будет монтироваться в переменную окружения DATABASE_URL:
```
apiVersion: v1
kind: Secret
metadata:
  name: back-prod-secrets
  labels:
    app: prod-back
data:
  DATABASE_URL: cG9zdGdyZXM6Ly9wb3N0Z3Jlczpub3RhcG9zdGdyZXNAZGI6NTQzMi9uZXdz
```

Создаем деплой и сервис для бэка:
```
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: prod-back-deploy
  name: prod-back
spec:
  replicas: 3
  selector:
    matchLabels:
      app: prod-back-pods
  template:
    metadata:
      labels:
        app: prod-back-pods
    spec:
      automountServiceAccountToken: false
      containers:
      - image: town0wl/netology-repo:backend
        imagePullPolicy: IfNotPresent
        name: backend
        resources:
          limits:
            cpu: 200m
            memory: 512Mi
          requests:
            cpu: 100m
            memory: 256Mi
        ports:
          - containerPort: 9000
        envFrom:
        - secretRef:
            name: back-prod-secrets
---
apiVersion: v1
kind: Service
metadata:
  name: back-srv
spec:
  selector:
    app: prod-back-pods
  ports:
    - protocol: TCP
      port: 9000
      targetPort: 9000
```

Бэк завелся:
```
[kube:homeworks]$ kl scale deploget pod,service,deploy,sts,pvc -n app-prod -o wide
NAME                            READY   STATUS    RESTARTS   AGE   IP              NODE    NOMINATED NODE   READINESS GATES
pod/prod-back-cc7d8c944-6bmtt   1/1     Running   0          3s    10.234.44.35    node2   <none>           <none>
pod/prod-back-cc7d8c944-bsvj5   1/1     Running   0          3s    10.234.154.22   node1   <none>           <none>
pod/prod-back-cc7d8c944-m2lzg   1/1     Running   0          3s    10.234.154.21   node1   <none>           <none>
pod/ss-postgres-0               1/1     Running   0          29m   10.234.154.18   node1   <none>           <none>

NAME               TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE     SELECTOR
service/back-srv   ClusterIP   10.111.113.119   <none>        9000/TCP   9m15s   app=prod-back-pods
service/db         ClusterIP   10.111.137.58    <none>        5432/TCP   31m     app=postgres-prod

NAME                        READY   UP-TO-DATE   AVAILABLE   AGE     CONTAINERS   IMAGES                          SELECTOR
deployment.apps/prod-back   3/3     3            3           8m44s   backend      town0wl/netology-repo:backend   app=prod-back-pods

NAME                           READY   AGE   CONTAINERS   IMAGES
statefulset.apps/ss-postgres   1/1     31m   postgres     postgres:12-alpine

NAME                                      STATUS   VOLUME             CAPACITY   ACCESS MODES   STORAGECLASS   AGE   VOLUMEMODE
persistentvolumeclaim/pvc-postgres-prod   Bound    pv-postgres-prod   2Gi        RWO                           26m   Filesystem
```

Проверяем отклик бэка и сервиса (при неудачном подключении к СУБД бэк падает с ошибкой):
```
[kube:homeworks]$ kl port-forward -n app-prod pod/prod-back-cc7d8c944-6bmtt 9002:9000 &
[2] 5233
[kube:homeworks]$ Forwarding from 127.0.0.1:9002 -> 9000
Forwarding from [::1]:9002 -> 9000

[kube:homeworks]$ curl http://127.0.0.1:9002
Handling connection for 9002
{"detail":"Not Found"}[kube:homeworks]$ 
[kube:homeworks]$ 
[kube:homeworks]$ kl port-forward -n app-prod service/back-srv 9000:9000 &
[3] 5247
[kube:homeworks]$ Forwarding from 127.0.0.1:9000 -> 9000
Forwarding from [::1]:9000 -> 9000

[kube:homeworks]$ curl http://127.0.0.1:9000
Handling connection for 9000
{"detail":"Not Found"}
```

Создаем деплой и сервис для фронта:
```
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: prod-front-deploy
  name: prod-front
spec:
  replicas: 3
  selector:
    matchLabels:
      app: prod-front-pods
  template:
    metadata:
      labels:
        app: prod-front-pods
    spec:
      automountServiceAccountToken: false
      containers:
      - image: town0wl/netology-repo:frontend
        imagePullPolicy: IfNotPresent
        name: frontend
        resources:
          limits:
            cpu: 200m
            memory: 512Mi
          requests:
            cpu: 100m
            memory: 256Mi
        ports:
          - containerPort: 80
        env:
          - name: BASE_URL
            value: "http://back-srv:9000"
---
apiVersion: v1
kind: Service
metadata:
  name: front-srv
spec:
  selector:
    app: prod-front-pods
  ports:
    - name: front-http
      protocol: TCP
      port: 8000
      targetPort: 80
```


Проверка отклика и состояния:
```
[kube:homeworks]$ kl get pod,service,deploy,sts,pvc -n app-prod -o wide
NAME                              READY   STATUS    RESTARTS   AGE   IP              NODE    NOMINATED NODE   READINESS GATES
pod/prod-back-cc7d8c944-6bmtt     1/1     Running   0          22m   10.234.44.35    node2   <none>           <none>
pod/prod-back-cc7d8c944-bsvj5     1/1     Running   0          22m   10.234.154.22   node1   <none>           <none>
pod/prod-back-cc7d8c944-m2lzg     1/1     Running   0          22m   10.234.154.21   node1   <none>           <none>
pod/prod-front-66f4785d84-hnvfl   1/1     Running   0          49s   10.234.44.36    node2   <none>           <none>
pod/prod-front-66f4785d84-qf4qq   1/1     Running   0          49s   10.234.44.37    node2   <none>           <none>
pod/prod-front-66f4785d84-s2jp5   1/1     Running   0          49s   10.234.154.23   node1   <none>           <none>
pod/ss-postgres-0                 1/1     Running   0          51m   10.234.154.18   node1   <none>           <none>

NAME                TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE   SELECTOR
service/back-srv    ClusterIP   10.111.113.119   <none>        9000/TCP   31m   app=prod-back-pods
service/db          ClusterIP   10.111.137.58    <none>        5432/TCP   54m   app=postgres-prod
service/front-srv   ClusterIP   10.111.229.208   <none>        8000/TCP   49s   app=prod-front-pods

NAME                         READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES                           SELECTOR
deployment.apps/prod-back    3/3     3            3           31m   backend      town0wl/netology-repo:backend    app=prod-back-pods
deployment.apps/prod-front   3/3     3            3           49s   frontend     town0wl/netology-repo:frontend   app=prod-front-pods

NAME                           READY   AGE   CONTAINERS   IMAGES
statefulset.apps/ss-postgres   1/1     54m   postgres     postgres:12-alpine

NAME                                      STATUS   VOLUME             CAPACITY   ACCESS MODES   STORAGECLASS   AGE   VOLUMEMODE
persistentvolumeclaim/pvc-postgres-prod   Bound    pv-postgres-prod   2Gi        RWO                           48m   Filesystem
[kube:homeworks]$ 
[kube:homeworks]$ 
[kube:homeworks]$ kl port-forward -n app-prod service/front-srv 8000:8000 &
[4] 5282
[kube:homeworks]$ Forwarding from 127.0.0.1:8000 -> 80
Forwarding from [::1]:8000 -> 80

[kube:homeworks]$ curl http://127.0.0.1:8000
Handling connection for 8000
<!DOCTYPE html>
<html lang="ru">
<head>
    <title>Список</title>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="/build/main.css" rel="stylesheet">
</head>
<body>
    <main class="b-page">
        <h1 class="b-page__title">Список</h1>
        <div class="b-page__content b-items js-list"></div>
    </main>
    <script src="/build/main.js"></script>
</body>
</html>
```